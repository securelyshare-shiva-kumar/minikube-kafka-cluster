apiVersion: v1
kind: ConfigMap
metadata:
  name: broker-config
  namespace: kafka
data:
  launch.sh: |-
    #!/bin/bash -e
    cp /carry/server.properties "$KAFKA_HOME/config/server.properties"
    # Allow specific kafka versions to perform any unique bootstrap operations
    OVERRIDE_FILE="/opt/overrides/${KAFKA_VERSION}.sh"
    if [[ -x "$OVERRIDE_FILE" ]]; then
        echo "Executing override file $OVERRIDE_FILE"
        eval "$OVERRIDE_FILE"
    fi
    
    # Store original IFS config, so we can restore it at various stages
    ORIG_IFS=$IFS
    
    if [[ -z "$KAFKA_ZOOKEEPER_CONNECT" ]]; then
        echo "ERROR: missing mandatory config: KAFKA_ZOOKEEPER_CONNECT"
        exit 1
    fi
    
    if [[ -z "$KAFKA_PORT" ]]; then
        export KAFKA_PORT=9092
    fi
    
    create-topics.sh &
    unset KAFKA_CREATE_TOPICS
    
    if [[ -z "$KAFKA_ADVERTISED_PORT" && \
      -z "$KAFKA_LISTENERS" && \
      -z "$KAFKA_ADVERTISED_LISTENERS" && \
      -S /var/run/docker.sock ]]; then
        KAFKA_ADVERTISED_PORT=$(docker port "$(hostname)" $KAFKA_PORT | sed -r 's/.*:(.*)/\1/g')
        export KAFKA_ADVERTISED_PORT
    fi
    
    if [[ -z "$KAFKA_BROKER_ID" ]]; then
        if [[ -n "$BROKER_ID_COMMAND" ]]; then
            KAFKA_BROKER_ID=$(eval "$BROKER_ID_COMMAND")
            export KAFKA_BROKER_ID
        else
            # By default auto allocate broker ID
            export KAFKA_BROKER_ID=-1
        fi
    fi
    
    if [[ -z "$KAFKA_LOG_DIRS" ]]; then
        export KAFKA_LOG_DIRS="/kafka/kafka-logs-$HOSTNAME"
    fi
    
    if [[ -n "$KAFKA_HEAP_OPTS" ]]; then
        sed -r -i 's/(export KAFKA_HEAP_OPTS)="(.*)"/\1="'"$KAFKA_HEAP_OPTS"'"/g' "$KAFKA_HOME/bin/kafka-server-start.sh"
        unset KAFKA_HEAP_OPTS
    fi
    
    if [[ -n "$HOSTNAME_COMMAND" ]]; then
        HOSTNAME_VALUE=$(eval "$HOSTNAME_COMMAND")
    
        # Replace any occurences of _{HOSTNAME_COMMAND} with the value
        IFS=$'\n'
        for VAR in $(env); do
            if [[ $VAR =~ ^KAFKA_ && "$VAR" =~ "_{HOSTNAME_COMMAND}" ]]; then
                eval "export ${VAR//_\{HOSTNAME_COMMAND\}/$HOSTNAME_VALUE}"
            fi
        done
        IFS=$ORIG_IFS
    fi
    
    if [[ -n "$PORT_COMMAND" ]]; then
        PORT_VALUE=$(eval "$PORT_COMMAND")
    
        # Replace any occurences of _{PORT_COMMAND} with the value
        IFS=$'\n'
        for VAR in $(env); do
            if [[ $VAR =~ ^KAFKA_ && "$VAR" =~ "_{PORT_COMMAND}" ]]; then
          eval "export ${VAR//_\{PORT_COMMAND\}/$PORT_VALUE}"
            fi
        done
        IFS=$ORIG_IFS
    fi
    
    if [[ -n "$RACK_COMMAND" && -z "$KAFKA_BROKER_RACK" ]]; then
        KAFKA_BROKER_RACK=$(eval "$RACK_COMMAND")
        export KAFKA_BROKER_RACK
    fi
    
    # Try and configure minimal settings or exit with error if there isn't enough information
    if [[ -z "$KAFKA_ADVERTISED_HOST_NAME$KAFKA_LISTENERS" ]]; then
        if [[ -n "$KAFKA_ADVERTISED_LISTENERS" ]]; then
            echo "ERROR: Missing environment variable KAFKA_LISTENERS. Must be specified when using KAFKA_ADVERTISED_LISTENERS"
            exit 1
        elif [[ -z "$HOSTNAME_VALUE" ]]; then
            echo "ERROR: No listener or advertised hostname configuration provided in environment."
            echo "       Please define KAFKA_LISTENERS / (deprecated) KAFKA_ADVERTISED_HOST_NAME"
            exit 1
        fi
    
        # Maintain existing behaviour
        # If HOSTNAME_COMMAND is provided, set that to the advertised.host.name value if listeners are not defined.
        export KAFKA_ADVERTISED_HOST_NAME="$HOSTNAME_VALUE"
    fi
    
    #Issue newline to config file in case there is not one already
    echo "" >> "$KAFKA_HOME/config/server.properties"
    
    (
        function updateConfig() {
            key=$1
            value=$2
            file=$3
    
            # Omit $value here, in case there is sensitive information
            echo "[Configuring] '$key' in '$file'"
    
            # If config exists in file, replace it. Otherwise, append to file.
            if grep -E -q "^#?$key=" "$file"; then
                sed -r -i "s@^#?$key=.*@$key=$value@g" "$file" #note that no config values may contain an '@' char
            else
                echo "$key=$value" >> "$file"
            fi
        }
    
        # Fixes #312
        # KAFKA_VERSION + KAFKA_HOME + grep -rohe KAFKA[A-Z0-0_]* /opt/kafka/bin | sort | uniq | tr '\n' '|'
        EXCLUSIONS="|KAFKA_VERSION|KAFKA_HOME|KAFKA_DEBUG|KAFKA_GC_LOG_OPTS|KAFKA_HEAP_OPTS|KAFKA_JMX_OPTS|KAFKA_JVM_PERFORMANCE_OPTS|KAFKA_LOG|KAFKA_OPTS|"
    
        # Read in env as a new-line separated array. This handles the case of env variables have spaces and/or carriage returns. See #313
        IFS=$'\n'
        for VAR in $(env)
        do
            env_var=$(echo "$VAR" | cut -d= -f1)
            if [[ "$EXCLUSIONS" = *"|$env_var|"* ]]; then
                echo "Excluding $env_var from broker config"
                continue
            fi
    
            if [[ $env_var =~ ^KAFKA_ ]]; then
                kafka_name=$(echo "$env_var" | cut -d_ -f2- | tr '[:upper:]' '[:lower:]' | tr _ .)
                updateConfig "$kafka_name" "${!env_var}" "$KAFKA_HOME/config/server.properties"
            fi
    
            if [[ $env_var =~ ^LOG4J_ ]]; then
                log4j_name=$(echo "$env_var" | tr '[:upper:]' '[:lower:]' | tr _ .)
                updateConfig "$log4j_name" "${!env_var}" "$KAFKA_HOME/config/log4j.properties"
            fi
        done
    )
    
    if [[ -n "$CUSTOM_INIT_SCRIPT" ]] ; then
      eval "$CUSTOM_INIT_SCRIPT"
    fi
    
    exec "$KAFKA_HOME/bin/kafka-server-start.sh" "$KAFKA_HOME/config/server.properties"

  server.properties: |-
    broker.id=0
    listeners=PLAINTEXT://:9092
    #advertised.listeners=PLAINTEXT://your.host.name:9092
    #listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
    num.network.threads=3
    num.io.threads=8
    socket.send.buffer.bytes=102400
    socket.receive.buffer.bytes=102400
    socket.request.max.bytes=104857600
    log.dirs=/kafka/kafka-logs-kafka-0
    num.partitions=1
    num.recovery.threads.per.data.dir=1
    offsets.topic.replication.factor=1
    transaction.state.log.replication.factor=1
    transaction.state.log.min.isr=1
    #log.flush.interval.messages=10000
    #log.flush.interval.ms=1000
    log.retention.hours=168
    #log.retention.bytes=1073741824
    log.segment.bytes=1073741824
    log.retention.check.interval.ms=300000
    zookeeper.connect=zookeeper-service:2181
    zookeeper.connection.timeout.ms=6000
    group.initial.rebalance.delay.ms=0
    advertised.port=9092
    port=9092
    auto.create.topics.enable=false
---
apiVersion: v1
kind: Service
metadata:
  name: bootstrap
  namespace: kafka
  labels:
    app: kafka
spec:
  ports:
  - port: 9092
    name: plaintext
  - port: 9999
    name: jmx
  clusterIP: None
  selector:
    app: kafka
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: kafka
spec:
  selector:
    matchLabels:
      app: kafka
  serviceName: "bootstrap"
  replicas: 1
  podManagementPolicy: OrderedReady
  template:
    metadata:
      labels:
        app: kafka
    spec:
      containers:
      - name: kafka
        image: wurstmeister/kafka:2.12-2.4.1
        imagePullPolicy: IfNotPresent
        command: ["bash"]
        args: ["/carry/launch.sh"]
        ports:
        - containerPort: 9092
          name: plaintext
        - containerPort: 9999
          name: jmx
        readinessProbe:
          tcpSocket:
            port: 9092
          initialDelaySeconds: 30
          timeoutSeconds: 30
        volumeMounts:
        - name: carry
          mountPath: /carry
        env:
        - name: BROKER_ID_COMMAND
          value: "hostname | cut -d'-' -f2"
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: "zookeeper-service:2181"
        - name: KAFKA_LISTENERS
          value: "PLAINTEXT://:9092"
      volumes:
      - name: carry
        configMap:
          name: broker-config
